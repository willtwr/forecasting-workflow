{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e49ee8",
   "metadata": {},
   "source": [
    "# Healthcare No Show Modeling\n",
    "\n",
    "- Train a ML model to forecast no show\n",
    "- Recall for positive data is low - about half of the time, patients that did not show up are missed.\n",
    "- Precision for positive data is very low - only about 35% of the predicted positive is correct.\n",
    "- Based on the data analysis, they do not demonstrate clear pattern(s) to differentiate no shows.\n",
    "    - Interpretation: a patient with certain traits is X% more likely to be no show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c40d67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")  # add src to environment path so that custom modules can be found\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from src.models.logistic_regression import LogisticRegressionClassifier\n",
    "from src.models.mlp import MLPClassifier\n",
    "from src.models.fttransformer import FTTransformerClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ba4811",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0a53f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_cross_val = 0\n",
    "full_dataset = torch.load(\n",
    "    # f\"../../data/healthcare_no_show/healthcare_datasets_base_{idx_cross_val}.pt\",\n",
    "    f\"../../data/healthcare_no_show/healthcare_datasets_cats_{idx_cross_val}.pt\",\n",
    "    # f\"../../data/healthcare_no_show/healthcare_datasets_reduced_{idx_cross_val}.pt\",\n",
    "    weights_only=False\n",
    ")\n",
    "train_dataset = full_dataset[\"train_dataset\"]\n",
    "val_dataset = full_dataset[\"val_dataset\"]\n",
    "feature_sizes = full_dataset[\"feature_cats\"]\n",
    "n_classes = full_dataset[\"class_size\"] if full_dataset[\"class_size\"] > 2 else 1\n",
    "class_weights = full_dataset[\"class_weights\"]\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9872d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "for feature, label in train_dataset:\n",
    "    train_x.append(feature.numpy())\n",
    "    train_y.append(label.numpy())\n",
    "\n",
    "train_x = np.vstack(train_x)\n",
    "# train_x = train_x[:, [8, 9, 1, 7]]\n",
    "train_y = np.vstack(train_y).flatten()\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "val_x = []\n",
    "val_y = []\n",
    "for feature, label in val_dataset:\n",
    "    val_x.append(feature.numpy())\n",
    "    val_y.append(label.numpy())\n",
    "\n",
    "val_x = np.vstack(val_x)\n",
    "# val_x = val_x[:, [8, 9, 1, 7]]\n",
    "val_y = np.vstack(val_y).flatten()\n",
    "\n",
    "print(val_x.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58445b6f",
   "metadata": {},
   "source": [
    "## Hyperparameters, functions, and model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb033e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tensorboard\n",
    "writer = SummaryWriter(f\"../../runs/healthcare_no_show_data{idx_cross_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d3bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializations that don't change with experiments\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.FloatTensor([class_weights[1]]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25d65786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ca42c8ce8f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset random seed\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff568aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "    # n_estimators=5,\n",
    "    criterion=\"log_loss\",\n",
    "    # max_depth=4,\n",
    "    class_weight='balanced',\n",
    "    random_state=1234,\n",
    "    n_jobs=4,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a029d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionClassifier(\n",
    "    feature_cats=feature_sizes,\n",
    "    num_classes=n_classes\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93af9217",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(\n",
    "    feature_cats=feature_sizes,\n",
    "    num_classes=n_classes,\n",
    "    num_hidden_neurons=192,\n",
    "    num_hidden_layers=1,\n",
    "    dropout=0.3\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc902e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FTTransformerClassifier(\n",
    "    feature_cats=feature_sizes,\n",
    "    num_classes=n_classes,\n",
    "    d_model=256,\n",
    "    num_encoder_layers=3,\n",
    "    dim_feedforward=384,\n",
    "    dropout=0.1\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cea0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate optimizer for bias, norm and inputs with weight decay = 0\n",
    "params_set1 = []\n",
    "params_set2 = []\n",
    "for name, param in model.named_parameters():\n",
    "    if \"cls_token\" not in name and \"embeddings\" not in name and \"bias\" not in name and \"norm\" not in name:\n",
    "        params_set1.append(param)\n",
    "    else:\n",
    "        params_set2.append(param)\n",
    "\n",
    "optimizer1 = torch.optim.AdamW(params_set1, lr=1e-4, weight_decay=1e-5)\n",
    "optimizer2 = torch.optim.AdamW(params_set2, lr=1e-4, weight_decay=0)\n",
    "optimizer = [optimizer1, optimizer2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19ec65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)  # Used by FT-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b8ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-2)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-4)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=1e-2)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1a2f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule learning rate reduction\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 60, 90], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9dac23",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2747bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6db21d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.7668, Val Loss: 0.7506\n",
      "Epoch [2/100], Loss: 0.7525, Val Loss: 0.7501\n",
      "Epoch [3/100], Loss: 0.7501, Val Loss: 0.7500\n",
      "Epoch [4/100], Loss: 0.7494, Val Loss: 0.7501\n",
      "Epoch [5/100], Loss: 0.7479, Val Loss: 0.7480\n",
      "Epoch [6/100], Loss: 0.7480, Val Loss: 0.7476\n",
      "Epoch [7/100], Loss: 0.7468, Val Loss: 0.7482\n",
      "Epoch [8/100], Loss: 0.7466, Val Loss: 0.7492\n",
      "Epoch [9/100], Loss: 0.7462, Val Loss: 0.7475\n",
      "Epoch [10/100], Loss: 0.7455, Val Loss: 0.7479\n",
      "Epoch [11/100], Loss: 0.7451, Val Loss: 0.7476\n",
      "Epoch [12/100], Loss: 0.7447, Val Loss: 0.7472\n",
      "Epoch [13/100], Loss: 0.7444, Val Loss: 0.7471\n",
      "Epoch [14/100], Loss: 0.7445, Val Loss: 0.7478\n",
      "Epoch [15/100], Loss: 0.7439, Val Loss: 0.7486\n",
      "Epoch [16/100], Loss: 0.7435, Val Loss: 0.7484\n",
      "Epoch [17/100], Loss: 0.7436, Val Loss: 0.7483\n",
      "Epoch [18/100], Loss: 0.7434, Val Loss: 0.7487\n",
      "Epoch [19/100], Loss: 0.7433, Val Loss: 0.7476\n",
      "Epoch [20/100], Loss: 0.7428, Val Loss: 0.7479\n",
      "Epoch [21/100], Loss: 0.7418, Val Loss: 0.7514\n",
      "Epoch [22/100], Loss: 0.7424, Val Loss: 0.7482\n",
      "Epoch [23/100], Loss: 0.7426, Val Loss: 0.7502\n",
      "Epoch [24/100], Loss: 0.7419, Val Loss: 0.7483\n",
      "Epoch [25/100], Loss: 0.7431, Val Loss: 0.7487\n",
      "Epoch [26/100], Loss: 0.7427, Val Loss: 0.7481\n",
      "Epoch [27/100], Loss: 0.7421, Val Loss: 0.7487\n",
      "Epoch [28/100], Loss: 0.7423, Val Loss: 0.7489\n",
      "Epoch [29/100], Loss: 0.7418, Val Loss: 0.7492\n",
      "Epoch [30/100], Loss: 0.7415, Val Loss: 0.7491\n",
      "Epoch [31/100], Loss: 0.7400, Val Loss: 0.7482\n",
      "Epoch [32/100], Loss: 0.7392, Val Loss: 0.7482\n",
      "Epoch [33/100], Loss: 0.7390, Val Loss: 0.7481\n",
      "Epoch [34/100], Loss: 0.7389, Val Loss: 0.7484\n",
      "Epoch [35/100], Loss: 0.7392, Val Loss: 0.7481\n",
      "Epoch [36/100], Loss: 0.7390, Val Loss: 0.7482\n",
      "Epoch [37/100], Loss: 0.7385, Val Loss: 0.7482\n",
      "Epoch [38/100], Loss: 0.7383, Val Loss: 0.7481\n",
      "Epoch [39/100], Loss: 0.7391, Val Loss: 0.7481\n",
      "Epoch [40/100], Loss: 0.7385, Val Loss: 0.7481\n",
      "Epoch [41/100], Loss: 0.7387, Val Loss: 0.7481\n",
      "Epoch [42/100], Loss: 0.7386, Val Loss: 0.7482\n",
      "Epoch [43/100], Loss: 0.7390, Val Loss: 0.7482\n",
      "Epoch [44/100], Loss: 0.7383, Val Loss: 0.7482\n",
      "Epoch [45/100], Loss: 0.7384, Val Loss: 0.7482\n",
      "Epoch [46/100], Loss: 0.7387, Val Loss: 0.7483\n",
      "Epoch [47/100], Loss: 0.7383, Val Loss: 0.7482\n",
      "Epoch [48/100], Loss: 0.7382, Val Loss: 0.7482\n",
      "Epoch [49/100], Loss: 0.7382, Val Loss: 0.7481\n",
      "Epoch [50/100], Loss: 0.7391, Val Loss: 0.7482\n",
      "Epoch [51/100], Loss: 0.7385, Val Loss: 0.7485\n",
      "Epoch [52/100], Loss: 0.7385, Val Loss: 0.7485\n",
      "Epoch [53/100], Loss: 0.7383, Val Loss: 0.7485\n",
      "Epoch [54/100], Loss: 0.7381, Val Loss: 0.7483\n",
      "Epoch [55/100], Loss: 0.7384, Val Loss: 0.7484\n",
      "Epoch [56/100], Loss: 0.7383, Val Loss: 0.7484\n",
      "Epoch [57/100], Loss: 0.7377, Val Loss: 0.7484\n",
      "Epoch [58/100], Loss: 0.7379, Val Loss: 0.7483\n",
      "Epoch [59/100], Loss: 0.7379, Val Loss: 0.7484\n",
      "Epoch [60/100], Loss: 0.7381, Val Loss: 0.7484\n",
      "Epoch [61/100], Loss: 0.7382, Val Loss: 0.7484\n",
      "Epoch [62/100], Loss: 0.7376, Val Loss: 0.7484\n",
      "Epoch [63/100], Loss: 0.7383, Val Loss: 0.7484\n",
      "Epoch [64/100], Loss: 0.7382, Val Loss: 0.7484\n",
      "Epoch [65/100], Loss: 0.7379, Val Loss: 0.7484\n",
      "Epoch [66/100], Loss: 0.7377, Val Loss: 0.7484\n",
      "Epoch [67/100], Loss: 0.7379, Val Loss: 0.7484\n",
      "Epoch [68/100], Loss: 0.7378, Val Loss: 0.7484\n",
      "Epoch [69/100], Loss: 0.7382, Val Loss: 0.7484\n",
      "Epoch [70/100], Loss: 0.7379, Val Loss: 0.7484\n",
      "Epoch [71/100], Loss: 0.7376, Val Loss: 0.7484\n",
      "Epoch [72/100], Loss: 0.7381, Val Loss: 0.7484\n",
      "Epoch [73/100], Loss: 0.7381, Val Loss: 0.7484\n",
      "Epoch [74/100], Loss: 0.7376, Val Loss: 0.7484\n",
      "Epoch [75/100], Loss: 0.7377, Val Loss: 0.7484\n",
      "Epoch [76/100], Loss: 0.7376, Val Loss: 0.7484\n",
      "Epoch [77/100], Loss: 0.7381, Val Loss: 0.7484\n",
      "Epoch [78/100], Loss: 0.7381, Val Loss: 0.7484\n",
      "Epoch [79/100], Loss: 0.7375, Val Loss: 0.7484\n",
      "Epoch [80/100], Loss: 0.7375, Val Loss: 0.7484\n",
      "Epoch [81/100], Loss: 0.7389, Val Loss: 0.7484\n",
      "Epoch [82/100], Loss: 0.7377, Val Loss: 0.7484\n",
      "Epoch [83/100], Loss: 0.7384, Val Loss: 0.7484\n",
      "Epoch [84/100], Loss: 0.7378, Val Loss: 0.7484\n",
      "Epoch [85/100], Loss: 0.7377, Val Loss: 0.7484\n",
      "Epoch [86/100], Loss: 0.7379, Val Loss: 0.7484\n",
      "Epoch [87/100], Loss: 0.7381, Val Loss: 0.7484\n",
      "Epoch [88/100], Loss: 0.7384, Val Loss: 0.7484\n",
      "Epoch [89/100], Loss: 0.7378, Val Loss: 0.7484\n",
      "Epoch [90/100], Loss: 0.7376, Val Loss: 0.7484\n",
      "Epoch [91/100], Loss: 0.7379, Val Loss: 0.7484\n",
      "Epoch [92/100], Loss: 0.7380, Val Loss: 0.7484\n",
      "Epoch [93/100], Loss: 0.7376, Val Loss: 0.7484\n",
      "Epoch [94/100], Loss: 0.7378, Val Loss: 0.7484\n",
      "Epoch [95/100], Loss: 0.7382, Val Loss: 0.7484\n",
      "Epoch [96/100], Loss: 0.7379, Val Loss: 0.7484\n",
      "Epoch [97/100], Loss: 0.7375, Val Loss: 0.7484\n",
      "Epoch [98/100], Loss: 0.7380, Val Loss: 0.7484\n",
      "Epoch [99/100], Loss: 0.7379, Val Loss: 0.7484\n",
      "Epoch [100/100], Loss: 0.7378, Val Loss: 0.7484\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for iter_idx, (features, labels) in enumerate(train_loader):\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        \n",
    "        if isinstance(optimizer, list):\n",
    "            [x.zero_grad() for x in optimizer]\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "        loss.backward()\n",
    "\n",
    "        if isinstance(optimizer, list):\n",
    "            [x.step() for x in optimizer]\n",
    "        else:\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if \"writer\" in globals():\n",
    "            writer.add_scalar(\"Loss/train\", loss.item(), epoch * len(train_loader) + iter_idx)\n",
    "    \n",
    "    if \"scheduler\" in globals():\n",
    "        scheduler.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for features, labels in val_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            val_loss += criterion(outputs, labels.unsqueeze(1)).item()\n",
    "\n",
    "        if \"writer\" in globals():\n",
    "            writer.add_scalar(\"Loss/val\", val_loss / len(val_loader), epoch)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95369f95",
   "metadata": {},
   "source": [
    "## Compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7cb83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(train_x.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(train_x.shape[1]), indices)\n",
    "plt.xlim([-1, train_x.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(val_x)\n",
    "print(classification_report(val_y, pred_y, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68579d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8605    0.7649    0.8099     17619\n",
      "         1.0     0.3572    0.5132    0.4212      4486\n",
      "\n",
      "    accuracy                         0.7138     22105\n",
      "   macro avg     0.6089    0.6390    0.6156     22105\n",
      "weighted avg     0.7584    0.7138    0.7310     22105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "preds = []\n",
    "trues = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for features, labels in val_loader:\n",
    "        features = features.to(device)\n",
    "        outputs = model(features)\n",
    "        predictions = torch.sigmoid(outputs.squeeze()).cpu().numpy()\n",
    "        preds.append(predictions)\n",
    "        trues.append(labels.numpy())\n",
    "\n",
    "preds = np.concat(preds, axis=0) > threshold\n",
    "trues = np.concat(trues, axis=0)\n",
    "print(classification_report(trues, preds, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caa4a2d",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* acc1 refers to accuracy of dataset 1\n",
    "\n",
    "Results of MLP:\n",
    "\n",
    "| model | opt type | LR | weight decay | acc | wprec | wrecall | wfscore | macprec | macrecall | macfscore |\n",
    "|----|----|----|----|----|----|----|----|----|----|----|\n",
    "| MLP | SGD | 1e-2 | 1e-2 | 0.7200 | 0.6991 | 0.7200 | 0.7057 | 0.6323 | 0.6076 | 0.6144 |\n",
    "|  | SGD | 1e-3 | 1e-2 | 0.7215 | 0.7009 | 0.7215 | 0.7076 | 0.6325 | 0.6084 | 0.6152 |\n",
    "|  | SGD | 1e-4 | 1e-2 | 0.7971 | 0.6353 | 0.7971 | 0.7070 | 0.3985 | 0.5000 | 0.4435 |\n",
    "|  | SGD | 1e-2 | 1e-4 | 0.7017 | 0.6807 | 0.7017 | 0.6797 | 0.6502 | 0.6109 | 0.6157 |\n",
    "|  | SGD | 1e-3 | 1e-4 | 0.6833 | 0.7665 | 0.6833 | 0.7101 | 0.6081 | 0.6538 | 0.6081 |\n",
    "|  | SGD | 1e-4 | 1e-4 | 0.7014 | 0.7391 | 0.7014 | 0.7170 | 0.5854 | 0.6055 | 0.5900 |\n",
    "|  | AdamW | 1e-3 | 1e-2 | 0.7097 | 0.6872 | 0.7097 | 0.6908 | 0.6423 | 0.6092 | 0.6155 |\n",
    "|  | AdamW | 1e-3 | 1e-4 | 0.7117 | 0.6894 | 0.7117 | 0.6933 | 0.6430 | 0.6103 | 0.6168 |\n",
    "|  | AdamW | 1e-3 | 1e-5 | 0.7127 | 0.6905 | 0.7127 | 0.6946 | 0.6434 | 0.6109 | 0.6175 |\n",
    "|  | AdamW | 1e-4 | 1e-2 | 0.7078 | 0.6858 | 0.7078 | 0.6879 | 0.6466 | 0.6109 | 0.6169 |\n",
    "|  | AdamW | 1e-4 | 1e-4 | 0.7079 | 0.6859 | 0.7079 | 0.6880 | 0.6466 | 0.6109 | 0.6169 |\n",
    "|  | AdamW | 1e-4 | 1e-5 | 0.7079 | 0.6859 | 0.7079 | 0.6880 | 0.6466 | 0.6109 | 0.6169 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c382522",
   "metadata": {},
   "source": [
    "## Store model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7311f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"../../models/healthcare_no_show/transformer_classifier_data{idx_cross_val}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
